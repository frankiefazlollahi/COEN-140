{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86ebfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d81c6",
   "metadata": {},
   "source": [
    "## Getting the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b48b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.dat', header=None, sep='\\t')\n",
    "\n",
    "# separating labels from features of training data\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_data = train_data.iloc[:, 1]\n",
    "\n",
    "test_data = pd.read_csv('test.dat', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5817bd4",
   "metadata": {},
   "source": [
    "## c-mer function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e713ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of c-mers for the row, taking c letters at a time\n",
    "# cmer refers to a count of characters\n",
    "# Given a row and parameter c, return the vector of c-mers associated with the row\n",
    "def cmer(row, c):\n",
    "    if len(row) < c:\n",
    "        return [row]\n",
    "    cmers = []\n",
    "    for i in range(len(row)-c+1):\n",
    "        cmers.append(row[i:(i+c)])\n",
    "    return cmers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7faef",
   "metadata": {},
   "source": [
    "## Function to build sparse matrix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57046f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# build sparse matrix from list of documents, where each is a list of words/terms in the document\n",
    "def build_matrix(data, num):\n",
    "    matrix = [cmer(row, num) for row in data]\n",
    "    nrows = len(matrix)\n",
    "    dictionary = {}\n",
    "    ID = 0\n",
    "    nnz = 0\n",
    "    for d in matrix:\n",
    "        wordlist = [x[0] for x in d]\n",
    "        nnz += len(set(wordlist))\n",
    "        d = wordlist\n",
    "        for w in d:\n",
    "            if w not in dictionary:\n",
    "                dictionary[w] = ID\n",
    "                ID += 1\n",
    "    ncols = len(dictionary)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype = int)\n",
    "    val = np.zeros(nnz, dtype = np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype = int)\n",
    "    \n",
    "    # row counter\n",
    "    i = 0\n",
    "    # non-zero counter\n",
    "    n = 0\n",
    "    \n",
    "    # transfering values\n",
    "    for d in matrix:\n",
    "        list_of_words = [x[0] for x in d]\n",
    "        count = Counter(list_of_words)\n",
    "        keys = list(k for k,_ in count.most_common())\n",
    "        l = len(keys)\n",
    "\n",
    "        for j, k in enumerate(keys):\n",
    "            ind[j + n] = dictionary[k]\n",
    "            val[j + n] = count[k]\n",
    "\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "        \n",
    "    matrix = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype = np.double)\n",
    "    matrix.sort_indices()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a3178",
   "metadata": {},
   "source": [
    "## Creating sparse matrices for training and test data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20b1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = np.append(train_data, test_data)\n",
    "\n",
    "# change c value to change length of cmers\n",
    "c = 3\n",
    "# creating sparse matrix of frequencies\n",
    "train_matrix = build_matrix(complete_data, c)[0:1566, :]\n",
    "test_matrix = build_matrix(complete_data, c)[1566:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359ebc8",
   "metadata": {},
   "source": [
    "## Classifying using various classifiers ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41172e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# classifier_1 = RandomForestClassifier()\n",
    "# classifier_1.fit(train_matrix, train_labels)\n",
    "# train_predict_1 = classifier_1.predict(train_matrix)\n",
    "# print(\"Random Forest MCC:\", matthews_corrcoef(train_labels, train_predict_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c805664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AdaBoost Classifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# classifier_2 = AdaBoostClassifier()\n",
    "# classifier_2.fit(train_matrix, train_labels)\n",
    "# train_predict_2 = classifier_2.predict(train_matrix)\n",
    "# print(\"AdaBoost MCC:\", matthews_corrcoef(train_labels, train_predict_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9afd3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Complement Naive Bayes\n",
    "# from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# classifier_3 = ComplementNB()\n",
    "# classifier_3.fit(train_matrix, train_labels)\n",
    "# train_predict_3 = classifier_3.predict(train_matrix)\n",
    "# print(\"Complement Naive Bayes MCC:\", matthews_corrcoef(train_labels, train_predict_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973062e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVM\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# classifier_4 = SVC(random_state = 0)\n",
    "# classifier_4.fit(train_matrix, train_labels)\n",
    "# train_predict_4 = classifier_4.predict(train_matrix)\n",
    "# print(\"SVM MCC:\", matthews_corrcoef(train_labels, train_predict_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ececd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = classifier_4.predict(test_matrix)\n",
    "# test_predictions_file = open('svm_output.txt', 'w+')\n",
    "# pd.Series(test_predictions).to_csv('svm_output.txt', index = False, header = None)\n",
    "# test_predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec162f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra-Trees Classifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# classifier_5 = ExtraTreesClassifier(n_estimators = 1000, max_features = None, )\n",
    "# classifier_5.fit(train_matrix, train_labels)\n",
    "# train_predict_5 = classifier_5.predict(train_matrix)\n",
    "# print(\"Extra-Trees MCC:\", matthews_corrcoef(train_labels, train_predict_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f123b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = classifier_5.predict(test_matrix)\n",
    "# test_predictions_file = open('ExtraTrees_output.txt', 'w+')\n",
    "# pd.Series(test_predictions).to_csv('ExtraTrees_output.txt', index = False, header = None)\n",
    "# test_predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5cd310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SGDClassifier\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# classifier_6 = SGDClassifier()\n",
    "# classifier_6.fit(train_matrix, train_labels)\n",
    "# train_predict_6 = classifier_6.predict(train_matrix)\n",
    "# print(\"SGD Classifier MCC:\", matthews_corrcoef(train_labels, train_predict_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7182670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier_7 = GradientBoostingClassifier(n_estimators = 10000, learning_rate = 0.1, max_depth = 3, random_state = 0)\n",
    "classifier_7.fit(train_matrix, train_labels)\n",
    "train_predict_7 = classifier_7.predict(train_matrix)\n",
    "print(\"Gradient Boosting Classifier MCC:\", matthews_corrcoef(train_labels, train_predict_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "197acd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = classifier_7.predict(test_matrix)\n",
    "test_predictions_file = open('GradientBoosting_output.txt', 'w+')\n",
    "pd.Series(test_predictions).to_csv('GradientBoosting_output.txt', index = False, header = None)\n",
    "test_predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36841222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7f1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# train_labels = le.fit_transform(train_labels)\n",
    "# classifier_8 = XGBClassifier(n_estimators = 100, learning_rate = 0.5, max_depth = 3, random_state = 0)\n",
    "# classifier_8.fit(train_matrix, train_labels)\n",
    "# train_predict_8 = classifier_8.predict(train_matrix)\n",
    "# print(\"XGBoost MCC: \", matthews_corrcoef(train_labels, train_predict_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02cd34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = classifier_8.predict(test_matrix)\n",
    "# test_predictions_file = open('xgboost_output.txt', 'w+')\n",
    "# pd.Series(test_predictions).to_csv('xgboost_output.txt', index = False, header = None)\n",
    "# test_predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13326690",
   "metadata": {},
   "source": [
    "## Predicting on test data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81bce831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = classifier_5.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df5374",
   "metadata": {},
   "source": [
    "## Writing predictions to file ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c39c63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions_file = open('output_8.txt', 'w+')\n",
    "# pd.Series(test_predictions).to_csv('output_8.txt', index = False, header = None)\n",
    "# test_predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fec2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output - random forest\n",
    "# output2 - adaboost\n",
    "# output3 - complement naive bayes\n",
    "# output4 - svm\n",
    "# output5 - extra trees\n",
    "# output6 - SGDClassifier\n",
    "# output7 - GradientBoostingClassifier\n",
    "# output8 - extra trees 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76935cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
